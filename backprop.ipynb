{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpOoxE2d-mOY"
      },
      "source": [
        "## Ejercicio teórico\n",
        "\n",
        "Sea una red neuronal de dos capas, la primera de 3 neuronas y la segunda de 1 con los parámetros inicializados con los siguientes valores:\n",
        "$$\n",
        "w^{(1)} =\n",
        "\\begin{pmatrix}\n",
        "0.1 & -0.5 \\\\\n",
        "-0.3 & -0.9 \\\\\n",
        "0.8 & 0.02\n",
        "\\end{pmatrix},\n",
        "b^{(1)} = \\begin{pmatrix}\n",
        "0.1 \\\\\n",
        "0.5 \\\\\n",
        "0.8\n",
        "\\end{pmatrix},\n",
        "w^{(2)} =\n",
        "\\begin{pmatrix}\n",
        "-0.4 & 0.2 & -0.5\n",
        "\\end{pmatrix},\n",
        "b^{(2)} = 0.7\n",
        "$$\n",
        "\n",
        "y donde cada capa calcula su salida vía\n",
        "\n",
        "$$\n",
        "y^{(i)} = \\sigma (w^{(i)} \\cdot x^{(i)}+b^{(i)})\n",
        "$$\n",
        "\n",
        "donde $\\sigma (z) = \\frac{1}{1+e^{-z}}$ es la función sigmoidea .\n",
        "\n",
        "\\\\\n",
        "Dada la observación $x=\\begin{pmatrix}\n",
        "1.8 \\\\\n",
        "-3.4\n",
        "\\end{pmatrix}$, $y=5$ y la función de costo $J(\\theta)=\\frac{1}{2}(\\hat{y}_\\theta-y)^2$, calcular las derivadas de J respecto de cada parámetro $w^{(1)}$, $w^{(2)}$, $b^{(1)}$, $b^{(2)}$.\n",
        "\n",
        "*Nota: Con una sigmoidea a la salida jamás va a poder estimar el 5 \"pedido\", pero eso no afecta al mecanismo de backpropagation!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Layer(object):\n",
        "  def __init__(self, n_in, n_out, non_linearity_class, optimizer_factory, rng, w_init=None, b_init=None):\n",
        "    self.activation = non_linearity_class()\n",
        "    self.optim = optimizer_factory()\n",
        "    #self.w = rng.standard_normal(size=(n_out, n_in))  * 0.1 # W shape is (n_out,n_in)\n",
        "    #self.b = rng.uniform(size=(n_out, 1))                   # b shape is (n_out, 1)\n",
        "    # Valores de peso y bias precalculados\n",
        "    self.w = w_init if w_init is not None else rng.standard_normal(size=(n_out, n_in)) * 0.1\n",
        "    self.b = b_init if b_init is not None else rng.uniform(size=(n_out, 1))\n",
        "    self.last_output = None\n",
        "    self.last_input = None\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.last_input = X\n",
        "    z = self.w @ X + self.b\n",
        "    self.last_output = self.activation.f(z)\n",
        "    print(\"--------------------------\")\n",
        "    print(\"Forward por capa z:\")\n",
        "    print(z)\n",
        "    print(\"Despues de la f de activación:\")\n",
        "    print(self.last_output)\n",
        "    print(\"--------------------------\")\n",
        "    return self.last_output\n",
        "\n",
        "  def backwards(self, dY):\n",
        "    dz = dY * self.activation.df()\n",
        "    dW = dz @ self.last_input.T\n",
        "    db = np.sum(dz, axis=1, keepdims=True)\n",
        "    dX = self.w.T @ dz\n",
        "    self.w, self.b = self.optim.update(self.w, self.b, dW, db)\n",
        "\n",
        "    # Mostrar derivadas parciales\n",
        "    print(\"--------------------------\")\n",
        "    print(\"Derivadas parciales respecto a W:\")\n",
        "    print(dW)\n",
        "    print(\"Derivadas parciales respecto a b:\")\n",
        "    print(\"--------------------------\")\n",
        "    print(db)\n",
        "    return dX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(object):\n",
        "  def __init__(self, dims, optimizer_factory, non_linearities, input_dim, rng_seed = None, precalc_weights=None, precalc_biases=None):\n",
        "    # check lengths\n",
        "    if len(dims) != len(non_linearities):\n",
        "      raise ValueError(\"dims' and Non_linearities' lengths do not match\")\n",
        "    # initialize RNG\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "    # construct a list of Layers with matching dimension and non-linear activation function\n",
        "    in_dims = [input_dim] + dims[:-1]\n",
        "    #self.layers = [Layer(n_in, n_out, non_linearity, optimizer_factory, rng)\n",
        "    #                for n_in,n_out,non_linearity in zip(in_dims,dims, non_linearities)]\n",
        "    self.layers = [Layer(n_in, n_out, non_linearity, optimizer_factory, rng, w_init, b_init)\n",
        "                    for n_in, n_out, non_linearity, w_init, b_init \n",
        "                    in zip(in_dims, dims, non_linearities, precalc_weights, precalc_biases)]\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    # X can be interpreted as the output of a previous layer\n",
        "    prediction = X\n",
        "    # sequentially apply forward pass\n",
        "    for layer in self.layers:\n",
        "      prediction = layer.forward(prediction)\n",
        "    return prediction\n",
        "\n",
        "  def update(self, cost_gradient):\n",
        "    # cost gradient is the cost derivative wrt last layer\n",
        "    dY = cost_gradient\n",
        "    # sequentially apply backwards update, in reversed order\n",
        "    for layer in reversed(self.layers):\n",
        "      dY = layer.backwards(dY)\n",
        "\n",
        "  def __repr__(self):\n",
        "    # super hardcoded\n",
        "    return \"MLP with layer sizes: \"+ \"-\".join(str(layer.b.shape[0]) for layer in self.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Optimizer(object):\n",
        "  def update(self, W, b, dW, db):\n",
        "    raise NotImplementedError(\"optimizer update rule not implemented\")\n",
        "\n",
        "class VGD(Optimizer):\n",
        "  def __init__(self, learning_rate):\n",
        "    self.lr = learning_rate\n",
        "    \n",
        "  def update(self, W_old, b_old, dW, db):\n",
        "    # vanilla GD: theta_t+1 = theta_t - alpha * gradient\n",
        "    W_new = W_old - self.lr * dW\n",
        "    b_new = b_old - self.lr * db\n",
        "    return W_new, b_new\n",
        "\n",
        "def factory_VGD(lr):\n",
        "  return lambda : VGD(lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NonLinearity(object):\n",
        "  def __init__(self):\n",
        "    self.last_z = None\n",
        "  def f(self, z):\n",
        "    raise NotImplementedError(\"function evaluation not implemented\")\n",
        "  def df(self):\n",
        "    raise NotImplementedError(\"function derivative not implemented\")\n",
        "  \n",
        "class Sigmoid(NonLinearity):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def f(self, z):\n",
        "    self.last_z = z\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "  def df(self):\n",
        "    return np.exp(-self.last_z) / (1 + np.exp(-self.last_z))**2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forward de entrada a dalida\n",
            "--------------------------\n",
            "Forward por capa z:\n",
            "[[1.98 ]\n",
            " [3.02 ]\n",
            " [2.172]]\n",
            "Despues de la f de activación:\n",
            "[[0.87868116]\n",
            " [0.95346953]\n",
            " [0.89770677]]\n",
            "--------------------------\n",
            "--------------------------\n",
            "Forward por capa z:\n",
            "[[0.09036805]]\n",
            "Despues de la f de activación:\n",
            "[[0.52257665]]\n",
            "--------------------------\n",
            "--------------------------\n",
            "Salida:  [[0.52257665]]\n",
            "--------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lr = 0.001\n",
        "rng_seed = 6543\n",
        "\n",
        "# Pesos y sesgos precalculados para cada capa\n",
        "precalc_weights = [\n",
        "    np.array([[0.1, -0.5], [-0.3, -0.9], [0.8, 0.02]]),  # Pesos para la primera capa (3x2)\n",
        "    np.array([[-0.4, 0.2, -0.5]])                        # Pesos para la segunda capa (1x3)\n",
        "]\n",
        "precalc_biases = [\n",
        "    np.array([[0.1], [0.5], [0.8]]),  # Bias para la primera capa (3x1)\n",
        "    np.array([[0.7]])                 # Bias para la segunda capa (1x1)\n",
        "]\n",
        "\n",
        "# Configuración del MLP:\n",
        "dims = [3, 1]  # 3 neuronas en la primera capa, 1 neurona en la segunda\n",
        "input_dim = 2  # 2 entradas (dimensión de entrada)\n",
        "optimizer_factory = lambda: VGD(learning_rate=lr) #No se usa porque el modelo esta pre entrenado\n",
        "non_linearities = [Sigmoid, Sigmoid]  # Activaciones sigmoides para ambas capas\n",
        "\n",
        "# Crear la MLP con pesos y sesgos precalculados\n",
        "mlp = MLP(dims, optimizer_factory, non_linearities, input_dim, precalc_weights=precalc_weights, precalc_biases=precalc_biases)\n",
        "\n",
        "# Input de ejemplo (2 características de entrada)\n",
        "X = np.array([[1.8], [-3.4]])  # Tamaño del input (2x1)\n",
        "\n",
        "# Predecir con el MLP\n",
        "print(\"Forward de entrada a dalida\")\n",
        "output = mlp.predict(X)\n",
        "print(\"--------------------------\")\n",
        "print(\"Salida: \",output)\n",
        "print(\"--------------------------\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backprop de salida a entrada\n",
            "Error cuadratico medio:  [[10.02365992]]\n",
            "--------------------------\n",
            "Derivadas parciales respecto a W:\n",
            "[[-0.98155159 -1.0650957  -1.0028046 ]]\n",
            "Derivadas parciales respecto a b:\n",
            "--------------------------\n",
            "[[-1.11707367]]\n",
            "--------------------------\n",
            "Derivadas parciales respecto a W:\n",
            "[[ 0.0857381  -0.16194975]\n",
            " [-0.01784139  0.0337004 ]\n",
            " [ 0.09232211 -0.1743862 ]]\n",
            "Derivadas parciales respecto a b:\n",
            "--------------------------\n",
            "[[ 0.04763228]\n",
            " [-0.00991188]\n",
            " [ 0.05129006]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Backprop de salida a entrada\")\n",
        "y_true = 5\n",
        "error = 1/2 * (output - y_true)**2\n",
        "print(\"Error cuadratico medio: \", error)\n",
        "mlp.update(output - y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from graphviz import Digraph\n",
        "import numpy as np\n",
        "\n",
        "def matrix_to_text(matrix):\n",
        "    \"\"\"Convierte una matriz numpy en una cadena de texto legible.\"\"\"\n",
        "    text_matrix = \"\\n[\"\n",
        "    for row in matrix:\n",
        "        text_matrix +=  \", \".join(f\"{v:.2f}\" for v in row) + \"\\n\"\n",
        "    text_matrix = text_matrix.rstrip(\"\\n\")\n",
        "    text_matrix += \"]\"\n",
        "    return text_matrix\n",
        "\n",
        "def generate_mlp_graph(mlp):\n",
        "    dot = Digraph()\n",
        "    dot.attr(rankdir='LR')  # Configurar la dirección del grafo de izquierda a derecha\n",
        "\n",
        "    # Crear el nodo de entrada X\n",
        "    dot.node(\"X\", \"Input X\")\n",
        "\n",
        "    # Iterar a través de las capas de la red\n",
        "    for i, layer in enumerate(mlp.layers):\n",
        "        input_size = layer.w.shape[1]\n",
        "        output_size = layer.w.shape[0]\n",
        "        activation_name = layer.activation.__class__.__name__\n",
        "\n",
        "        # Convertir los pesos y sesgos en un texto legible\n",
        "        weights_text = matrix_to_text(layer.w)\n",
        "        bias_text = matrix_to_text(layer.b)\n",
        "\n",
        "        # Crear nodos para la capa actual con matrices en texto legible\n",
        "        dot.node(f\"Layer {i+1} input\", f\"Layer {i+1} input ({input_size})\")\n",
        "        dot.node(f\"Layer {i+1} output\", \n",
        "                 f\"Layer {i+1} output ({output_size})\\nActivation: {activation_name}\\nWeights {layer.w.shape[0]}x{layer.w.shape[1]}: {weights_text}\\nBias {layer.b.shape[0]}x{layer.b.shape[1]}: {bias_text}\")\n",
        "\n",
        "        # Conectar la entrada con la salida de la misma capa\n",
        "        dot.edge(f\"Layer {i+1} input\", f\"Layer {i+1} output\", label=f\"Layer {i+1}\")\n",
        "\n",
        "        # Conectar la salida de la capa anterior con la entrada de la actual\n",
        "        if i > 0:\n",
        "            dot.edge(f\"Layer {i} output\", f\"Layer {i+1} input\")\n",
        "        else:\n",
        "            # Conectar el nodo de entrada X con la primera capa\n",
        "            dot.edge(\"X\", f\"Layer {i+1} input\")\n",
        "\n",
        "    # Crear el nodo de salida y_hat para la predicción\n",
        "    dot.node(\"y_hat\", \"Predicted Output y_hat\")\n",
        "    dot.edge(f\"Layer {len(mlp.layers)} output\", \"y_hat\")\n",
        "\n",
        "    # Crear el nodo de salida verdadera y\n",
        "    dot.node(\"y_true\", \"True Output y\")\n",
        "\n",
        "    # Crear el nodo de la función de pérdida que conecta y_hat y y_true\n",
        "    dot.node(\"Loss\", \"Loss Function\")\n",
        "    dot.edge(\"y_hat\", \"Loss\", label=\"y_hat\")\n",
        "    dot.edge(\"y_true\", \"Loss\", label=\"y_true\")\n",
        "\n",
        "    return dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 12.1.2 (20240928.0832)\n",
              " -->\n",
              "<!-- Pages: 1 -->\n",
              "<svg width=\"1402pt\" height=\"253pt\"\n",
              " viewBox=\"0.00 0.00 1402.48 252.66\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 248.66)\">\n",
              "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-248.66 1398.48,-248.66 1398.48,4 -4,4\"/>\n",
              "<!-- X -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>X</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"39.58\" cy=\"-122.33\" rx=\"39.58\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"39.58\" y=\"-117.28\" font-family=\"Times,serif\" font-size=\"14.00\">Input X</text>\n",
              "</g>\n",
              "<!-- Layer 1 input -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>Layer 1 input</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"190.54\" cy=\"-122.33\" rx=\"74.38\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"190.54\" y=\"-117.28\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 input (2)</text>\n",
              "</g>\n",
              "<!-- X&#45;&gt;Layer 1 input -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>X&#45;&gt;Layer 1 input</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M79.33,-122.33C87.12,-122.33 95.6,-122.33 104.27,-122.33\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"104.24,-125.83 114.24,-122.33 104.24,-118.83 104.24,-125.83\"/>\n",
              "</g>\n",
              "<!-- Layer 1 output -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>Layer 1 output</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"432.73\" cy=\"-122.33\" rx=\"89.8\" ry=\"122.33\"/>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-191.53\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 output (3)</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-175.03\" font-family=\"Times,serif\" font-size=\"14.00\">Activation: Sigmoid</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-158.53\" font-family=\"Times,serif\" font-size=\"14.00\">Weights 3x2: </text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-142.03\" font-family=\"Times,serif\" font-size=\"14.00\">[0.10, &#45;0.50</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-125.53\" font-family=\"Times,serif\" font-size=\"14.00\">&#45;0.30, &#45;0.90</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-109.03\" font-family=\"Times,serif\" font-size=\"14.00\">0.80, 0.02]</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-92.53\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 3x1: </text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-76.03\" font-family=\"Times,serif\" font-size=\"14.00\">[0.10</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-59.53\" font-family=\"Times,serif\" font-size=\"14.00\">0.50</text>\n",
              "<text text-anchor=\"middle\" x=\"432.73\" y=\"-43.03\" font-family=\"Times,serif\" font-size=\"14.00\">0.80]</text>\n",
              "</g>\n",
              "<!-- Layer 1 input&#45;&gt;Layer 1 output -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>Layer 1 input&#45;&gt;Layer 1 output</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M265.24,-122.33C286.02,-122.33 309,-122.33 331.07,-122.33\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"331.01,-125.83 341.01,-122.33 331.01,-118.83 331.01,-125.83\"/>\n",
              "<text text-anchor=\"middle\" x=\"303.93\" y=\"-125.53\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1</text>\n",
              "</g>\n",
              "<!-- Layer 2 input -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>Layer 2 input</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"633.91\" cy=\"-122.33\" rx=\"74.38\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"633.91\" y=\"-117.28\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 input (3)</text>\n",
              "</g>\n",
              "<!-- Layer 1 output&#45;&gt;Layer 2 input -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>Layer 1 output&#45;&gt;Layer 2 input</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M522.83,-122.33C531.07,-122.33 539.41,-122.33 547.61,-122.33\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"547.58,-125.83 557.58,-122.33 547.58,-118.83 547.58,-125.83\"/>\n",
              "</g>\n",
              "<!-- Layer 2 output -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>Layer 2 output</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"876.1\" cy=\"-122.33\" rx=\"89.8\" ry=\"75.66\"/>\n",
              "<text text-anchor=\"middle\" x=\"876.1\" y=\"-158.53\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 output (1)</text>\n",
              "<text text-anchor=\"middle\" x=\"876.1\" y=\"-142.03\" font-family=\"Times,serif\" font-size=\"14.00\">Activation: Sigmoid</text>\n",
              "<text text-anchor=\"middle\" x=\"876.1\" y=\"-125.53\" font-family=\"Times,serif\" font-size=\"14.00\">Weights 1x3: </text>\n",
              "<text text-anchor=\"middle\" x=\"876.1\" y=\"-109.03\" font-family=\"Times,serif\" font-size=\"14.00\">[&#45;0.40, 0.20, &#45;0.50]</text>\n",
              "<text text-anchor=\"middle\" x=\"876.1\" y=\"-92.53\" font-family=\"Times,serif\" font-size=\"14.00\">Bias 1x1: </text>\n",
              "<text text-anchor=\"middle\" x=\"876.1\" y=\"-76.03\" font-family=\"Times,serif\" font-size=\"14.00\">[0.70]</text>\n",
              "</g>\n",
              "<!-- Layer 2 input&#45;&gt;Layer 2 output -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>Layer 2 input&#45;&gt;Layer 2 output</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M708.61,-122.33C729.39,-122.33 752.37,-122.33 774.45,-122.33\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"774.38,-125.83 784.38,-122.33 774.38,-118.83 774.38,-125.83\"/>\n",
              "<text text-anchor=\"middle\" x=\"747.3\" y=\"-125.53\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2</text>\n",
              "</g>\n",
              "<!-- y_hat -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>y_hat</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"1099.8\" cy=\"-122.33\" rx=\"96.9\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"1099.8\" y=\"-117.28\" font-family=\"Times,serif\" font-size=\"14.00\">Predicted Output y_hat</text>\n",
              "</g>\n",
              "<!-- Layer 2 output&#45;&gt;y_hat -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>Layer 2 output&#45;&gt;y_hat</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M966.32,-122.33C974.51,-122.33 982.86,-122.33 991.19,-122.33\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"991,-125.83 1001,-122.33 991,-118.83 991,-125.83\"/>\n",
              "</g>\n",
              "<!-- Loss -->\n",
              "<g id=\"node8\" class=\"node\">\n",
              "<title>Loss</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"1330.84\" cy=\"-88.33\" rx=\"63.63\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"1330.84\" y=\"-83.28\" font-family=\"Times,serif\" font-size=\"14.00\">Loss Function</text>\n",
              "</g>\n",
              "<!-- y_hat&#45;&gt;Loss -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>y_hat&#45;&gt;Loss</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M1176.75,-111.06C1204.44,-106.95 1235.53,-102.33 1262.43,-98.34\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"1262.8,-101.82 1272.18,-96.89 1261.77,-94.9 1262.8,-101.82\"/>\n",
              "<text text-anchor=\"middle\" x=\"1231.96\" y=\"-108.53\" font-family=\"Times,serif\" font-size=\"14.00\">y_hat</text>\n",
              "</g>\n",
              "<!-- y_true -->\n",
              "<g id=\"node7\" class=\"node\">\n",
              "<title>y_true</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"1099.8\" cy=\"-68.33\" rx=\"63.63\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"1099.8\" y=\"-63.28\" font-family=\"Times,serif\" font-size=\"14.00\">True Output y</text>\n",
              "</g>\n",
              "<!-- y_true&#45;&gt;Loss -->\n",
              "<g id=\"edge7\" class=\"edge\">\n",
              "<title>y_true&#45;&gt;Loss</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M1163.35,-70.74C1189.87,-72.06 1221.09,-74.02 1249.21,-76.83 1253.8,-77.29 1258.53,-77.82 1263.29,-78.39\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"1262.53,-81.82 1272.89,-79.6 1263.41,-74.88 1262.53,-81.82\"/>\n",
              "<text text-anchor=\"middle\" x=\"1231.96\" y=\"-80.03\" font-family=\"Times,serif\" font-size=\"14.00\">y_true</text>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x10864e060>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dot = generate_mlp_graph(mlp)\n",
        "#dot.render('mlp_graph', format='png', view=True) \n",
        "display(dot)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "amia-j4FGlwjZ-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
